# NLP bootcamp (1st, 18.10.13 ~ 18.12.22)
모두의연구소 flipped school 과정 중 하나인 NLP bootcamp에서 발표한 paper 목록과 그 자료들입니다.

+ participant : 강재욱, 권성은, 김경환, 김동화, 김민섭, 김수정, 김승일, 모경현, 박정배, 박희경, 염혜원, 원종국, 윤훈상, 이명재, 이승재, 이일구, 이현준, 정미연, 최우정, 조주현
+ faciliator : 김보섭

## Schedule
아래의 논문 순서를 따라 읽으실 뿐들은 "A Neural Conversational Model"은 꼭 읽지않아도 되며, "Convolutional Sequence to Sequence Learning"의 경우, week06에 해당하는 paper를 다 읽고 읽으시는 게 좋습니다. **다시 말하자면, week05와 week06만 순서를 바꿔 읽으시면 됩니다.**

### Week01 (18/10/06)
Orientation
### Week02 (18/10/13)
+ Convolutional Neural Networks for Sentence Classification
  - Presenter : 최우정 
  - Paper : https://arxiv.org/abs/1408.5882
  - Material : [Convolutional Neural Networks for Sentence Classification_최우정.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week02/Convolutional%20Neural%20Networks%20for%20Sentence%20Classification_%EC%B5%9C%EC%9A%B0%EC%A0%95.pdf)
+ Character-level Convolutional Networks for Text Classification
  - Presenter : 박정배
  - Paper : https://arxiv.org/abs/1509.01626
  - Material :  [Character-level convolutional networks for text classification_박정배.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week02/Character-level%20convolutional%20networks%20for%20text%20classification_%EB%B0%95%EC%A0%95%EB%B0%B0.pdf)
### Week03 (18/10/20)
+ Character-Aware Neural Language Models
  - Presenter : 이일구
  - Paper : https://arxiv.org/abs/1508.06615
  - Material : [Character-Aware Neural Language Models_이일구.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week03/Character-Aware%20Neural%20Language%20Models_%EC%9D%B4%EC%9D%BC%EA%B5%AC.pdf)
+ A Convolutional Neural Network for Modelling Sentences
  - Presenter : 윤훈상
  - Paper : https://arxiv.org/abs/1404.2188
  - Material : [A Convolutional Neural Network for Modelling Sentences_윤훈상.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week03/A%20Convolutional%20Neural%20Network%20for%20Modelling%20Sentences_%EC%9C%A4%ED%9B%88%EC%83%81.pdf)
### Week04 (18/10/27)
+ Learning Phrase Representation using RNN Encoder-Decoder for Statistical Machine Translation
	- Presenter : 염혜원
	- Paper : https://arxiv.org/abs/1406.1078
	- Material : [Learning Phrase Representation using RNN Encoder-Decoder for Statistical Machine Translation_염혜정.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week04/Learning%20Phrase%20Representation%20using%20RNN%20Encoder-Decoder%20for%20Statistical%20Machine%20Translation_%EC%97%BC%ED%98%9C%EC%A0%95.pdf) 
+ Sequence to Sequence Learning with Neural Networks
	- Presenter : 권성은
	- Paper : https://arxiv.org/abs/1409.3215
	- Material :  [Sequence to Sequence Learning with Neural Networks_권성은.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week04/Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks_%EA%B6%8C%EC%84%B1%EC%9D%80.pdf)
### Week05 (18/11/03)
+ A Neural Conversational Model
	- Presenter : 원종국
	- Paper : https://arxiv.org/abs/1506.05869
	- Material : [A Neural Conversational Model_원종국.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week05/A%20Neural%20Conversational%20Model_%EC%9B%90%EC%A2%85%EA%B5%AD.pdf)
+ Convolutional Sequence to Sequence Learning
	- Presenter : 모경현
	- Paper : https://arxiv.org/abs/1705.03122
	- Material : [Convolutional Sequence to Sequence Learning_모경현.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week05/Convolutional%20Sequence%20to%20Sequence%20Learning_%EB%AA%A8%EA%B2%BD%ED%98%84.pdf) 
### Week06 (18/11/10)
+ Neural Machine Translation by Jointly Learning to Align and Translate
	- Presenter : 박희경
	- Paper : https://arxiv.org/abs/1409.0473
	- Material : [Neural Machine Translation by Jointly Learning to Align and Translate_박희경.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week06/Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate_%EB%B0%95%ED%9D%AC%EA%B2%BD.pdf)
+ Effective Approaches to Attention-based Neural Machine Translation
	- Presenter : 김보섭
	- Paper : https://arxiv.org/abs/1508.04025
	- Material : [Effective Approaches to Attention-based Neural Machine Translation_김보섭.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week06/Effective%20Approaches%20to%20Attention-based%20Neural%20Machine%20Translation_%EA%B9%80%EB%B3%B4%EC%84%AD.pdf)
### Week07 (18/11/17)
+ A Structured Self-attentive Sentence Embedding
  - Presenter : 정미연
  - Paper : https://arxiv.org/abs/1703.03130
  - Material : [A Structured Self-attentive Sentence Embedding_정미연.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week07/A%20Structured%20Self-attentive%20Sentence%20Embedding_%EC%A0%95%EB%AF%B8%EC%97%B0.pdf)
+ Attention is All You Need
  - Presenter : 이승재
  - Paper : https://arxiv.org/abs/1706.03762
  - Material : [Attention is All You Need_이승재.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week07/Attention%20is%20All%20You%20Need_%EC%9D%B4%EC%8A%B9%EC%9E%AC.pdf) 
### Week08 (18/11/24)
+ Show and Tell: A Neural Image Caption Generator
	- Presenter : 김경환
	- Paper : https://arxiv.org/abs/1411.4555
	- Material : [Show and Tell_A Neural Image Caption Generator_김경환.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week08/Show%20and%20Tell_A%20Neural%20Image%20Caption%20Generator_%EA%B9%80%EA%B2%BD%ED%99%98.pdf)
+ Show, Attend and Tell: Neural Image Caption Generation with Visual Attention
	- Presenter : 이현준
	- Paper : https://arxiv.org/abs/1502.03044
	- Material : [Show, Attend and Tell_Neural Image Caption Generation with Visual Attention_이현준.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week08/Show%2C%20Attend%20and%20Tell_Neural%20Image%20Caption%20Generation%20with%20Visual%20Attention_%EC%9D%B4%ED%98%84%EC%A4%80.pdf)
### Week09 (18/12/01)
+ Memory Networks
	- Presenter : 이명재
	- Paper : https://arxiv.org/abs/1410.3916
	- Material : [Memory Networks_이명재.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week09/Memory%20Networks_%EC%9D%B4%EB%AA%85%EC%9E%AC.pdf)
+ End-To-End Memory Networks
	- Presenter : 조주현
	- Paper : https://arxiv.org/abs/1503.08895
	- Material : [End-To-End Memory Networks_조주현.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week09/End-To-End%20Memory%20Networks_%EC%A1%B0%EC%A3%BC%ED%98%84.pdf)
### Week10 (18/12/08)
+ Ask Me Anything: Dynamic Memory Networks for Natural Language Processing
	- Presenter : 김승일
	- Paper : https://arxiv.org/abs/1506.07285
	- Material : [Ask Me Anything_Dynamic Memory Networks for Natural Language Processing_김승일.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week10/Ask%20Me%20Anything_Dynamic%20Memory%20Networks%20for%20Natural%20Language%20Processing_%EA%B9%80%EC%8A%B9%EC%9D%BC.pdf)
+ Enriching Word Vectors with Subword Information
	- Presenter :  김보섭
	- Paper : https://arxiv.org/abs/1607.04606
	- Material : [Enriching Word Vectors with Subword Information_김보섭.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week10/Enriching%20Word%20Vectors%20with%20Subword%20Information_%EA%B9%80%EB%B3%B4%EC%84%AD.pdf)
### Week11 (18/12/15)
졸업식
### Week12 (18/12/22)
+ Deep contextualized word representations
	- Presenter : 김보섭
	- Paper : https://arxiv.org/abs/1802.05365
	- Material : [Deep contextualized word representations_김보섭.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week12/Deep%20contextualized%20word%20representations_%EA%B9%80%EB%B3%B4%EC%84%AD.pdf)
+ BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
	- Presenter : 김동화
	- Paper : https://arxiv.org/abs/1810.04805
	- Material : [BERT_Pre-training of Deep Bidirectional Transformers for Language Understanding_김동화.pdf](https://github.com/modulabs/NLP-bootcamp/blob/master/1st/week12/BERT_Pre-training%20of%20Deep%20Bidirectional%20Transformers%20for%20Language%20Understanding_%EA%B9%80%EB%8F%99%ED%99%94.pdf) 

